{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ğŸµ DEMO: PhÃ¡t Hiá»‡n NgÃ¡y tá»« Audio File\n",
        "\n",
        "Script Ä‘Æ¡n giáº£n Ä‘á»ƒ test model vá»›i file audio\n",
        "\n",
        "## ğŸ“ HÆ°á»›ng dáº«n sá»­ dá»¥ng:\n",
        "1. **Thay Ä‘á»•i Ä‘Æ°á»ng dáº«n file audio** á»Ÿ cell bÃªn dÆ°á»›i (dÃ²ng `AUDIO_FILE`)\n",
        "2. **Cháº¡y táº¥t cáº£ cÃ¡c cell** (Cell â†’ Run All)\n",
        "3. **Xem káº¿t quáº£** á»Ÿ cuá»‘i notebook\n",
        "\n",
        "## âš™ï¸ YÃªu cáº§u:\n",
        "- File model: `Model_LeNet5_PhatHienNgay_100x64.h5` pháº£i cÃ³ trong cÃ¹ng thÆ° má»¥c\n",
        "- File audio: WAV, MP3, M4A, FLAC, OGG, AAC\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… ÄÃ£ cáº¥u hÃ¬nh!\n",
            "ğŸ“‚ File audio: /Users/thanhhuongtran/Documents/lab-proj/mentor/D2T/1_16.wav\n",
            "ğŸ¤– File model: /Users/thanhhuongtran/Documents/lab-proj/mentor/D2T/Model_Custom_PhatHienNgay_100x64.h5\n"
          ]
        }
      ],
      "source": [
        "# ============================================\n",
        "# âš™ï¸ Cáº¤U HÃŒNH - CHá»ˆ Cáº¦N THAY ÄÆ¯á»œNG DáºªN FILE á» ÄÃ‚Y\n",
        "# ============================================\n",
        "\n",
        "# ğŸ‘‡ THAY ÄÆ¯á»œNG DáºªN FILE AUDIO Cá»¦A Báº N VÃ€O ÄÃ‚Y ğŸ‘‡\n",
        "AUDIO_FILE = \"/Users/thanhhuongtran/Documents/lab-proj/mentor/D2T/1_16.wav\"  # VÃ­ dá»¥: \"audio/test.wav\" hoáº·c \"/Users/name/audio.mp3\"\n",
        "\n",
        "MODEL_FILE = \"/Users/thanhhuongtran/Documents/lab-proj/mentor/D2T/Model_Custom_PhatHienNgay_100x64.h5\"\n",
        "\n",
        "# TÃªn cÃ¡c lá»›p - QUAN TRá»ŒNG: Pháº£i khá»›p vá»›i label mapping trong training!\n",
        "# Trong training: Others=0, Normal Snore=1, OSA Snore=2\n",
        "# Sau khi to_categorical(3): Index 0=Others, Index 1=Normal Snore, Index 2=OSA Snore\n",
        "CLASS_NAMES = ['Others', 'Normal Snore', 'OSA Snore']  # âš ï¸ ÄÃ£ sá»­a láº¡i Ä‘á»ƒ khá»›p vá»›i training!\n",
        "\n",
        "print(\"âœ… ÄÃ£ cáº¥u hÃ¬nh!\")\n",
        "print(f\"ğŸ“‚ File audio: {AUDIO_FILE}\")\n",
        "print(f\"ğŸ¤– File model: {MODEL_FILE}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pywavelets in /Users/thanhhuongtran/miniconda3/envs/osa/lib/python3.10/site-packages (1.8.0)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /Users/thanhhuongtran/miniconda3/envs/osa/lib/python3.10/site-packages (from pywavelets) (2.1.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install pywavelets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… ÄÃ£ import táº¥t cáº£ thÆ° viá»‡n!\n"
          ]
        }
      ],
      "source": [
        "# Import cÃ¡c thÆ° viá»‡n cáº§n thiáº¿t\n",
        "import numpy as np\n",
        "import librosa\n",
        "import pywt\n",
        "from scipy import ndimage\n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.decomposition import PCA\n",
        "import os\n",
        "\n",
        "print(\"âœ… ÄÃ£ import táº¥t cáº£ thÆ° viá»‡n!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… ÄÃ£ tÃ¬m tháº¥y file audio: /Users/thanhhuongtran/Documents/lab-proj/mentor/D2T/1_16.wav\n",
            "âœ… ÄÃ£ tÃ¬m tháº¥y file model: /Users/thanhhuongtran/Documents/lab-proj/mentor/D2T/Model_Custom_PhatHienNgay_100x64.h5\n"
          ]
        }
      ],
      "source": [
        "# Kiá»ƒm tra file cÃ³ tá»“n táº¡i khÃ´ng\n",
        "if not os.path.exists(AUDIO_FILE):\n",
        "    print(f\"âŒ Lá»–I: KhÃ´ng tÃ¬m tháº¥y file audio!\")\n",
        "    print(f\"   ÄÆ°á»ng dáº«n: {AUDIO_FILE}\")\n",
        "    print(f\"\\nğŸ’¡ HÃ£y thay Ä‘á»•i AUDIO_FILE á»Ÿ cell trÃªn!\")\n",
        "else:\n",
        "    print(f\"âœ… ÄÃ£ tÃ¬m tháº¥y file audio: {AUDIO_FILE}\")\n",
        "\n",
        "if not os.path.exists(MODEL_FILE):\n",
        "    print(f\"âŒ Lá»–I: KhÃ´ng tÃ¬m tháº¥y file model!\")\n",
        "    print(f\"   ÄÆ°á»ng dáº«n: {MODEL_FILE}\")\n",
        "else:\n",
        "    print(f\"âœ… ÄÃ£ tÃ¬m tháº¥y file model: {MODEL_FILE}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ“¦ Äang load model tá»«: /Users/thanhhuongtran/Documents/lab-proj/mentor/D2T/Model_Custom_PhatHienNgay_100x64.h5...\n",
            "âœ… ÄÃ£ load model thÃ nh cÃ´ng!\n"
          ]
        }
      ],
      "source": [
        "# Load model\n",
        "print(f\"ğŸ“¦ Äang load model tá»«: {MODEL_FILE}...\")\n",
        "model = load_model(MODEL_FILE)\n",
        "print(\"âœ… ÄÃ£ load model thÃ nh cÃ´ng!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… ÄÃ£ Ä‘á»‹nh nghÄ©a hÃ m xá»­ lÃ½ audio giá»‘ng há»‡t training data!\n"
          ]
        }
      ],
      "source": [
        "# HÃ m xá»­ lÃ½ audio giá»‘ng há»‡t training data (theo áº£nh)\n",
        "# Training code: coeff, freqs = pywt.cwt(data, scales, 'morl')\n",
        "#                pca = PCA(n_components=64)\n",
        "#                coeff = pca.fit_transform(coeff)\n",
        "#                np.save(output_file, coeff)\n",
        "def process_audio_segment(audio_segment, sampling_rate=8000):\n",
        "    \"\"\"\n",
        "    Xá»­ lÃ½ má»™t Ä‘oáº¡n audio 1 giÃ¢y giá»‘ng há»‡t training data\n",
        "    - Downsample vá» 8kHz\n",
        "    - CWT vá»›i Morlet wavelet, scales 1-100\n",
        "    - PCA giáº£m vá» 64 components\n",
        "    - Output: (100, 64) hoáº·c shape tÆ°Æ¡ng tá»± file .npy\n",
        "    \"\"\"\n",
        "    # Äáº£m báº£o audio Ä‘Ãºng Ä‘á»™ dÃ i 1 giÃ¢y (8000 samples á»Ÿ 8kHz)\n",
        "    target_samples = sampling_rate * 1  # 1 giÃ¢y\n",
        "    if len(audio_segment) != target_samples:\n",
        "        if len(audio_segment) < target_samples:\n",
        "            # Pad náº¿u ngáº¯n hÆ¡n\n",
        "            audio_segment = np.pad(audio_segment, (0, target_samples - len(audio_segment)), mode='constant')\n",
        "        else:\n",
        "            # Cáº¯t náº¿u dÃ i hÆ¡n\n",
        "            audio_segment = audio_segment[:target_samples]\n",
        "    \n",
        "    # Continuous Wavelet Transform (CWT) vá»›i Morlet wavelet\n",
        "    # Scales tá»« 1 Ä‘áº¿n 100 (giá»‘ng training)\n",
        "    scales = np.arange(1, 101)\n",
        "    coeff, freqs = pywt.cwt(audio_segment, scales, 'morl')\n",
        "    # coeff shape: (100, time_samples) - 100 scales, time_samples thá»i gian\n",
        "    \n",
        "    # Ãp dá»¥ng PCA - GIá»NG Há»†T TRAINING CODE (theo áº£nh)\n",
        "    # Training code: pca.fit_transform(coeff) vá»›i coeff shape (100, time_samples)\n",
        "    # PCA.fit_transform(coeff) sáº½:\n",
        "    #   - Coi má»—i column (time step) lÃ  má»™t sample vá»›i 100 features (scales)\n",
        "    #   - Giáº£m tá»« 100 features xuá»‘ng 64 components\n",
        "    #   - Káº¿t quáº£: (64, time_samples)\n",
        "    pca = PCA(n_components=64)\n",
        "    coeff_pca = pca.fit_transform(coeff)  # Shape: (64, time_samples)\n",
        "    \n",
        "    # Transpose Ä‘á»ƒ cÃ³ (time_samples, 64) - giá»‘ng nhÆ° khi load tá»« .npy\n",
        "    # Training data file .npy cÃ³ shape (100, 64) sau khi Ä‘Æ°á»£c xá»­ lÃ½\n",
        "    coeff_pca = coeff_pca.T  # Shape: (time_samples, 64)\n",
        "    \n",
        "    # Resize vá» (100, 64) - giá»‘ng training data\n",
        "    # Training data file .npy cÃ³ shape (100, 64)\n",
        "    # Cáº§n resize time_samples vá» 100, giá»¯ nguyÃªn 64 components\n",
        "    if coeff_pca.shape != (100, 64):\n",
        "        # Resize cáº£ 2 chiá»u vá» Ä‘Ãºng (100, 64)\n",
        "        zoom_0 = 100 / coeff_pca.shape[0]\n",
        "        zoom_1 = 64 / coeff_pca.shape[1]\n",
        "        coeff_resized = ndimage.zoom(coeff_pca, \n",
        "                                     (zoom_0, zoom_1),\n",
        "                                     order=1)\n",
        "    else:\n",
        "        coeff_resized = coeff_pca\n",
        "    \n",
        "    # Äáº£m báº£o shape cuá»‘i cÃ¹ng chÃ­nh xÃ¡c lÃ  (100, 64)\n",
        "    if coeff_resized.shape != (100, 64):\n",
        "        # Force resize náº¿u váº«n khÃ´ng Ä‘Ãºng\n",
        "        coeff_resized = ndimage.zoom(coeff_resized, \n",
        "                                     (100 / coeff_resized.shape[0], 64 / coeff_resized.shape[1]),\n",
        "                                     order=1)\n",
        "    \n",
        "    # Káº¿t quáº£: (100, 64) - giá»‘ng file .npy trong training\n",
        "    return coeff_resized.astype(np.float32)\n",
        "\n",
        "def process_audio_file(audio_path, segment_length=1.0, sampling_rate=8000):\n",
        "    \"\"\"\n",
        "    Xá»­ lÃ½ file audio giá»‘ng há»‡t training data\n",
        "    - Load raw audio (.wav, .mp3, ...)\n",
        "    - Downsample vá» 8kHz\n",
        "    - Chia thÃ nh cÃ¡c Ä‘oáº¡n 1 giÃ¢y (giá»‘ng training: 1000ms)\n",
        "    - Xá»­ lÃ½ tá»«ng Ä‘oáº¡n: CWT -> PCA -> (100, 64)\n",
        "    \"\"\"\n",
        "    print(f\"ğŸ“‚ Äang Ä‘á»c file audio: {audio_path}\")\n",
        "    \n",
        "    # Load audio file vÃ  downsample vá» 8kHz (giá»‘ng training)\n",
        "    y, sr = librosa.load(audio_path, sr=sampling_rate, mono=True)\n",
        "    duration = len(y) / sr\n",
        "    print(f\"   âœ… ÄÃ£ load audio: {duration:.2f} giÃ¢y, sample rate: {sr} Hz (Ä‘Ã£ downsample vá» 8kHz)\")\n",
        "    \n",
        "    # Chia audio thÃ nh cÃ¡c Ä‘oáº¡n 1 giÃ¢y (giá»‘ng training: duration_ms=1000)\n",
        "    segment_samples = int(segment_length * sampling_rate)  # 8000 samples = 1 giÃ¢y\n",
        "    segments = []\n",
        "    \n",
        "    num_segments = int(len(y) / segment_samples)\n",
        "    if len(y) % segment_samples > 0:\n",
        "        num_segments += 1\n",
        "    \n",
        "    print(f\"   ğŸ”„ Chia audio thÃ nh {num_segments} Ä‘oáº¡n (má»—i Ä‘oáº¡n {segment_length}s = {segment_samples} samples)\")\n",
        "    \n",
        "    for i in range(num_segments):\n",
        "        start = i * segment_samples\n",
        "        end = start + segment_samples\n",
        "        \n",
        "        if end > len(y):\n",
        "            # Äoáº¡n cuá»‘i: pad náº¿u cáº§n\n",
        "            segment = y[start:]\n",
        "            if len(segment) < segment_samples:\n",
        "                segment = np.pad(segment, (0, segment_samples - len(segment)), mode='constant')\n",
        "        else:\n",
        "            segment = y[start:end]\n",
        "        \n",
        "        # Xá»­ lÃ½ Ä‘oáº¡n audio: CWT -> PCA -> (100, 64)\n",
        "        spectrogram = process_audio_segment(segment, sampling_rate=sampling_rate)\n",
        "        segments.append(spectrogram)\n",
        "    \n",
        "    print(f\"   âœ… ÄÃ£ táº¡o {len(segments)} spectrograms vá»›i shape {segments[0].shape}\")\n",
        "    return segments\n",
        "\n",
        "print(\"âœ… ÄÃ£ Ä‘á»‹nh nghÄ©a hÃ m xá»­ lÃ½ audio giá»‘ng há»‡t training data!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "ğŸ” ÄANG PHÃ‚N TÃCH AUDIO...\n",
            "==================================================\n",
            "ğŸ“ Quy trÃ¬nh: Load raw audio -> Downsample 8kHz -> Chia 1s/Ä‘oáº¡n -> CWT -> PCA -> (100,64)\n",
            "==================================================\n",
            "ğŸ“‚ Äang Ä‘á»c file audio: /Users/thanhhuongtran/Documents/lab-proj/mentor/D2T/1_16.wav\n",
            "   âœ… ÄÃ£ load audio: 1.00 giÃ¢y, sample rate: 8000 Hz (Ä‘Ã£ downsample vá» 8kHz)\n",
            "   ğŸ”„ Chia audio thÃ nh 1 Ä‘oáº¡n (má»—i Ä‘oáº¡n 1.0s = 8000 samples)\n",
            "   âœ… ÄÃ£ táº¡o 1 spectrograms vá»›i shape (100, 64)\n",
            "\n",
            "ğŸ” Debug: Shape cá»§a spectrograms:\n",
            "   Spectrogram 0: (100, 64)\n",
            "\n",
            "âœ… ÄÃ£ chuáº©n bá»‹ 1 Ä‘oáº¡n cho model!\n",
            "âœ… Shape má»—i Ä‘oáº¡n: (100, 64, 1)\n"
          ]
        }
      ],
      "source": [
        "# Xá»­ lÃ½ audio file giá»‘ng há»‡t training data\n",
        "print(\"=\"*50)\n",
        "print(\"ğŸ” ÄANG PHÃ‚N TÃCH AUDIO...\")\n",
        "print(\"=\"*50)\n",
        "print(\"ğŸ“ Quy trÃ¬nh: Load raw audio -> Downsample 8kHz -> Chia 1s/Ä‘oáº¡n -> CWT -> PCA -> (100,64)\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Xá»­ lÃ½ audio: chia thÃ nh cÃ¡c Ä‘oáº¡n 1 giÃ¢y vÃ  xá»­ lÃ½ tá»«ng Ä‘oáº¡n\n",
        "spectrograms = process_audio_file(AUDIO_FILE, segment_length=1.0, sampling_rate=8000)\n",
        "\n",
        "# Kiá»ƒm tra shape trÆ°á»›c khi reshape\n",
        "print(f\"\\nğŸ” Debug: Shape cá»§a spectrograms:\")\n",
        "for i, spec in enumerate(spectrograms[:3]):  # Chá»‰ in 3 cÃ¡i Ä‘áº§u\n",
        "    print(f\"   Spectrogram {i}: {spec.shape}\")\n",
        "\n",
        "# Reshape Ä‘á»ƒ phÃ¹ há»£p vá»›i input cá»§a model (100, 64, 1)\n",
        "spectrograms_reshaped = np.array([spec.reshape(100, 64, 1) for spec in spectrograms])\n",
        "\n",
        "print(f\"\\nâœ… ÄÃ£ chuáº©n bá»‹ {len(spectrograms_reshaped)} Ä‘oáº¡n cho model!\")\n",
        "print(f\"âœ… Shape má»—i Ä‘oáº¡n: {spectrograms_reshaped[0].shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ¤– Äang cháº¡y model predict cho 1 Ä‘oáº¡n...\n",
            "âœ… ÄÃ£ hoÃ n táº¥t predict 1 Ä‘oáº¡n!\n",
            "ğŸ“Š Káº¿t quáº£ Ä‘Æ°á»£c tÃ­nh tá»« trung bÃ¬nh cá»§a 1 Ä‘oáº¡n\n"
          ]
        }
      ],
      "source": [
        "# Cháº¡y model predict cho táº¥t cáº£ cÃ¡c Ä‘oáº¡n\n",
        "print(f\"\\nğŸ¤– Äang cháº¡y model predict cho {len(spectrograms_reshaped)} Ä‘oáº¡n...\")\n",
        "all_predictions = model.predict(spectrograms_reshaped, verbose=0)\n",
        "\n",
        "# TÃ­nh káº¿t quáº£ trung bÃ¬nh tá»« táº¥t cáº£ cÃ¡c Ä‘oáº¡n\n",
        "avg_predictions = np.mean(all_predictions, axis=0)\n",
        "class_idx = np.argmax(avg_predictions)\n",
        "confidence = float(avg_predictions[class_idx])\n",
        "class_name = CLASS_NAMES[class_idx]\n",
        "\n",
        "print(f\"âœ… ÄÃ£ hoÃ n táº¥t predict {len(all_predictions)} Ä‘oáº¡n!\")\n",
        "print(f\"ğŸ“Š Káº¿t quáº£ Ä‘Æ°á»£c tÃ­nh tá»« trung bÃ¬nh cá»§a {len(all_predictions)} Ä‘oáº¡n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "ğŸ“Š Káº¾T QUáº¢ Dá»° ÄOÃN (Trung bÃ¬nh tá»« táº¥t cáº£ cÃ¡c Ä‘oáº¡n)\n",
            "==================================================\n",
            "\n",
            "ğŸ¯ Lá»›p dá»± Ä‘oÃ¡n: Others\n",
            "ğŸ“ˆ Äá»™ tin cáº­y: 99.79%\n",
            "ğŸ“¦ Sá»‘ Ä‘oáº¡n Ä‘Ã£ phÃ¢n tÃ­ch: 1\n",
            "\n",
            "ğŸ“‹ XÃ¡c suáº¥t trung bÃ¬nh cho táº¥t cáº£ cÃ¡c lá»›p:\n",
            "--------------------------------------------------\n",
            "ğŸ‘‰ Others         :  99.79% â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘\n",
            "   Normal Snore   :   0.03% â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘\n",
            "   OSA Snore      :   0.17% â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘\n",
            "\n",
            "ğŸ“Š Káº¿t quáº£ tá»«ng Ä‘oáº¡n:\n",
            "--------------------------------------------------\n",
            "   Äoáº¡n 1: Others (99.8%)\n",
            "\n",
            "ğŸ“ˆ PhÃ¢n bá»‘ káº¿t quáº£ tá»«ng Ä‘oáº¡n:\n",
            "   Others: 1/1 Ä‘oáº¡n (100.0%)\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "# Hiá»ƒn thá»‹ káº¿t quáº£ chi tiáº¿t\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"ğŸ“Š Káº¾T QUáº¢ Dá»° ÄOÃN (Trung bÃ¬nh tá»« táº¥t cáº£ cÃ¡c Ä‘oáº¡n)\")\n",
        "print(\"=\"*50)\n",
        "print(f\"\\nğŸ¯ Lá»›p dá»± Ä‘oÃ¡n: {class_name}\")\n",
        "print(f\"ğŸ“ˆ Äá»™ tin cáº­y: {confidence*100:.2f}%\")\n",
        "print(f\"ğŸ“¦ Sá»‘ Ä‘oáº¡n Ä‘Ã£ phÃ¢n tÃ­ch: {len(all_predictions)}\")\n",
        "\n",
        "print(f\"\\nğŸ“‹ XÃ¡c suáº¥t trung bÃ¬nh cho táº¥t cáº£ cÃ¡c lá»›p:\")\n",
        "print(\"-\" * 50)\n",
        "for i, (name, prob) in enumerate(zip(CLASS_NAMES, avg_predictions)):\n",
        "    bar_length = int(prob * 30)  # Bar dÃ i 30 kÃ½ tá»±\n",
        "    bar = \"â–ˆ\" * bar_length + \"â–‘\" * (30 - bar_length)\n",
        "    marker = \"ğŸ‘‰\" if i == class_idx else \"  \"\n",
        "    print(f\"{marker} {name:15s}: {prob*100:6.2f}% {bar}\")\n",
        "\n",
        "# Hiá»ƒn thá»‹ káº¿t quáº£ tá»«ng Ä‘oáº¡n\n",
        "print(f\"\\nğŸ“Š Káº¿t quáº£ tá»«ng Ä‘oáº¡n:\")\n",
        "print(\"-\" * 50)\n",
        "segment_results = []\n",
        "for idx, pred in enumerate(all_predictions):\n",
        "    seg_class = CLASS_NAMES[np.argmax(pred)]\n",
        "    seg_conf = float(pred[np.argmax(pred)])\n",
        "    segment_results.append(seg_class)\n",
        "    if idx < 5:  # Chá»‰ hiá»ƒn thá»‹ 5 Ä‘oáº¡n Ä‘áº§u\n",
        "        print(f\"   Äoáº¡n {idx+1}: {seg_class} ({seg_conf*100:.1f}%)\")\n",
        "\n",
        "if len(all_predictions) > 5:\n",
        "    print(f\"   ... vÃ  {len(all_predictions)-5} Ä‘oáº¡n khÃ¡c\")\n",
        "\n",
        "# Äáº¿m sá»‘ lÆ°á»£ng má»—i class\n",
        "from collections import Counter\n",
        "class_counts = Counter(segment_results)\n",
        "print(f\"\\nğŸ“ˆ PhÃ¢n bá»‘ káº¿t quáº£ tá»«ng Ä‘oáº¡n:\")\n",
        "for cls, count in class_counts.items():\n",
        "    print(f\"   {cls}: {count}/{len(segment_results)} Ä‘oáº¡n ({count/len(segment_results)*100:.1f}%)\")\n",
        "\n",
        "print(\"=\"*50)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ“¦ Káº¿t quáº£ dáº¡ng dictionary:\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'predicted_class': 'Others',\n",
              " 'confidence': 99.79,\n",
              " 'num_segments': 1,\n",
              " 'all_probabilities': {'Others': 99.79,\n",
              "  'Normal Snore': 0.03,\n",
              "  'OSA Snore': 0.17},\n",
              " 'segment_distribution': {'Others': 1}}"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Hiá»ƒn thá»‹ káº¿t quáº£ dáº¡ng dictionary (Ä‘á»ƒ dá»… sá»­ dá»¥ng)\n",
        "results = {\n",
        "    'predicted_class': class_name,\n",
        "    'confidence': round(confidence * 100, 2),\n",
        "    'num_segments': len(all_predictions),\n",
        "    'all_probabilities': {\n",
        "        CLASS_NAMES[0]: round(float(avg_predictions[0]) * 100, 2),\n",
        "        CLASS_NAMES[1]: round(float(avg_predictions[1]) * 100, 2),\n",
        "        CLASS_NAMES[2]: round(float(avg_predictions[2]) * 100, 2)\n",
        "    },\n",
        "    'segment_distribution': dict(class_counts)\n",
        "}\n",
        "\n",
        "print(\"\\nğŸ“¦ Káº¿t quáº£ dáº¡ng dictionary:\")\n",
        "results\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "osa",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
